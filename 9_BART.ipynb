{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "feca8dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import BartModel, BartTokenizer, BartConfig\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scienceplots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(['science', 'notebook', 'grid', 'ieee'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e6f821",
   "metadata": {},
   "source": [
    "- Bart uses a standard seq2seq translation architecture with a bidirectional encoder (like Bert) and a left-to-right decoder (like GPT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b348faf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc3d882e3c8344ce8ba286ed344e7232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.51k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d60d5c3d9494a258e888fa3bd4a9cbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcf59e0bfe334ffd8aae0ca8d6a51f60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cba0aa1c6174ef2bd7b0d3f8bd51a44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd1a2c28bb5c457eae7932643293e212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = 'facebook/bart-large-xsum'\n",
    "model = BartModel.from_pretrained(model_name)\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "config = BartConfig.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95aecfb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartModel(\n",
       "  (shared): Embedding(50265, 1024, padding_idx=1)\n",
       "  (encoder): BartEncoder(\n",
       "    (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
       "    (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "    (layers): ModuleList(\n",
       "      (0-11): 12 x BartEncoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (activation_fn): GELUActivation()\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): BartDecoder(\n",
       "    (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
       "    (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "    (layers): ModuleList(\n",
       "      (0-11): 12 x BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e14e8f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartConfig {\n",
       "  \"activation_dropout\": 0.1,\n",
       "  \"activation_function\": \"gelu\",\n",
       "  \"add_bias_logits\": false,\n",
       "  \"add_final_layer_norm\": false,\n",
       "  \"architectures\": [\n",
       "    \"BartModel\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classif_dropout\": 0.1,\n",
       "  \"classifier_dropout\": 0.0,\n",
       "  \"d_model\": 1024,\n",
       "  \"decoder_attention_heads\": 16,\n",
       "  \"decoder_ffn_dim\": 4096,\n",
       "  \"decoder_layerdrop\": 0.0,\n",
       "  \"decoder_layers\": 12,\n",
       "  \"decoder_start_token_id\": 2,\n",
       "  \"dropout\": 0.1,\n",
       "  \"early_stopping\": true,\n",
       "  \"encoder_attention_heads\": 16,\n",
       "  \"encoder_ffn_dim\": 4096,\n",
       "  \"encoder_layerdrop\": 0.0,\n",
       "  \"encoder_layers\": 12,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"forced_bos_token_id\": 0,\n",
       "  \"forced_eos_token_id\": 2,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"LABEL_0\",\n",
       "    \"1\": \"LABEL_1\",\n",
       "    \"2\": \"LABEL_2\"\n",
       "  },\n",
       "  \"init_std\": 0.02,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"label2id\": {\n",
       "    \"LABEL_0\": 0,\n",
       "    \"LABEL_1\": 1,\n",
       "    \"LABEL_2\": 2\n",
       "  },\n",
       "  \"max_position_embeddings\": 1024,\n",
       "  \"model_type\": \"bart\",\n",
       "  \"no_repeat_ngram_size\": 3,\n",
       "  \"normalize_before\": false,\n",
       "  \"num_beams\": 4,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"scale_embedding\": false,\n",
       "  \"task_specific_params\": {\n",
       "    \"summarization\": {\n",
       "      \"length_penalty\": 1.0,\n",
       "      \"max_length\": 128,\n",
       "      \"min_length\": 12,\n",
       "      \"num_beams\": 4\n",
       "    },\n",
       "    \"summarization_cnn\": {\n",
       "      \"length_penalty\": 2.0,\n",
       "      \"max_length\": 142,\n",
       "      \"min_length\": 56,\n",
       "      \"num_beams\": 4\n",
       "    },\n",
       "    \"summarization_xsum\": {\n",
       "      \"length_penalty\": 1.0,\n",
       "      \"max_length\": 62,\n",
       "      \"min_length\": 11,\n",
       "      \"num_beams\": 6\n",
       "    }\n",
       "  },\n",
       "  \"transformers_version\": \"4.31.0\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50265\n",
       "}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b05a25ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<s>',\n",
       " 'eos_token': '</s>',\n",
       " 'unk_token': '<unk>',\n",
       " 'sep_token': '</s>',\n",
       " 'pad_token': '<pad>',\n",
       " 'cls_token': '<s>',\n",
       " 'mask_token': '<mask>'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8eda4d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 80])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'The Bart model was proposed in BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension by Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov and Luke Zettlemoyer on 29 Oct, 2019.'\n",
    "\n",
    "batch_inputs = tokenizer(text, return_tensors='pt')\n",
    "input_ids = batch_inputs['input_ids']\n",
    "input_ids.shape\n",
    "# (batch_size, sentence length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f67ed4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(BaseModelOutput(last_hidden_state=tensor([[[ 0.0161,  0.0217,  0.0252,  ..., -0.0050, -0.0082, -0.0064],\n",
       "          [-0.1113,  0.1126, -0.1159,  ..., -0.0657, -0.1892,  0.0033],\n",
       "          [ 0.0120,  0.2809, -0.1886,  ..., -0.0165, -0.1217,  0.0316],\n",
       "          ...,\n",
       "          [ 0.0761, -0.2055, -0.3899,  ..., -0.2413, -0.0148, -0.1123],\n",
       "          [-0.0069,  0.0174,  0.0142,  ...,  0.0099, -0.0057, -0.0035],\n",
       "          [ 0.1635,  0.1311,  0.0902,  ..., -0.0374, -0.0921,  0.0596]]],\n",
       "        grad_fn=<NativeLayerNormBackward0>), hidden_states=None, attentions=None),\n",
       " torch.Size([1, 80, 1024]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "encoder_outputs = model.get_encoder()(input_ids)\n",
    "encoder_outputs, encoder_outputs.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d59e358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2]]),\n",
       " tensor([[[ 0.0161,  0.0217,  0.0252,  ..., -0.0050, -0.0082, -0.0064],\n",
       "          [-0.1113,  0.1126, -0.1159,  ..., -0.0657, -0.1892,  0.0033],\n",
       "          [ 0.0120,  0.2809, -0.1886,  ..., -0.0165, -0.1217,  0.0316],\n",
       "          ...,\n",
       "          [ 0.0761, -0.2055, -0.3899,  ..., -0.2413, -0.0148, -0.1123],\n",
       "          [-0.0069,  0.0174,  0.0142,  ...,  0.0099, -0.0057, -0.0035],\n",
       "          [ 0.1635,  0.1311,  0.0902,  ..., -0.0374, -0.0921,  0.0596]]],\n",
       "        grad_fn=<NativeLayerNormBackward0>))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_ids, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "85d6b6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1011, 509, 509, 509, 509, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 608, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 608, 1011, 608, 1011, 608, 1011, 608, 1011, 608, 1011, 608, 1011, 608, 1011, 608, 1011, 608, 1011, 608, 1011, 608, 1011, 1011, 1011, 1011, 1011, 1011]\n"
     ]
    }
   ],
   "source": [
    "decoder_start_token = config.decoder_start_token_id\n",
    "decoder_input_ids = torch.tensor([[decoder_start_token]], dtype=torch.long)\n",
    "\n",
    "generated_tokens = []\n",
    "\n",
    "for _ in range(100):\n",
    "    decoder_outputs = model.get_decoder()(input_ids=decoder_input_ids,\n",
    "                                          encoder_hidden_states=encoder_outputs.last_hidden_state)\n",
    "    logits = decoder_outputs[0]\n",
    "    next_token_id = logits.argmax(-1)[:, -1]\n",
    "    decoder_input_ids = torch.cat([decoder_input_ids, next_token_id.unsqueeze(-1)], dim=-1)\n",
    "    generated_tokens.append(next_token_id.item())\n",
    "    if next_token_id.item() == tokenizer.eos_token_id:\n",
    "        break\n",
    "print(generated_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6c9eaad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' ball One One One One ball ball ball ball ball ball ball ball ball ball ball ball ball ball doing ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball doing ball doing ball doing ball doing ball doing ball doing ball doing ball doing ball doing ball doing ball doing ball ball ball ball ball ball'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_text = tokenizer.decode(generated_tokens)\n",
    "output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6c077e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before append input_ids.shape torch.Size([1, 80])\n",
      "after append input_ids.shape torch.Size([1, 81])\n",
      "before append input_ids.shape torch.Size([1, 81])\n",
      "after append input_ids.shape torch.Size([1, 82])\n",
      "before append input_ids.shape torch.Size([1, 82])\n",
      "after append input_ids.shape torch.Size([1, 83])\n",
      "before append input_ids.shape torch.Size([1, 83])\n",
      "after append input_ids.shape torch.Size([1, 84])\n",
      "before append input_ids.shape torch.Size([1, 84])\n",
      "after append input_ids.shape torch.Size([1, 85])\n",
      "before append input_ids.shape torch.Size([1, 85])\n",
      "after append input_ids.shape torch.Size([1, 86])\n",
      "before append input_ids.shape torch.Size([1, 86])\n",
      "after append input_ids.shape torch.Size([1, 87])\n",
      "before append input_ids.shape torch.Size([1, 87])\n",
      "after append input_ids.shape torch.Size([1, 88])\n",
      "before append input_ids.shape torch.Size([1, 88])\n",
      "after append input_ids.shape torch.Size([1, 89])\n",
      "before append input_ids.shape torch.Size([1, 89])\n",
      "after append input_ids.shape torch.Size([1, 90])\n"
     ]
    }
   ],
   "source": [
    "text = 'The Bart model was proposed in BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension by Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov and Luke Zettlemoyer on 29 Oct, 2019.'\n",
    "model_inputs = tokenizer(text, return_tensors='pt')\n",
    "input_ids = model_inputs.input_ids\n",
    "\n",
    "n_steps = 10\n",
    "top_x = 5\n",
    "\n",
    "\n",
    "decoder_start_token = model.config.decoder_start_token_id\n",
    "decoder_input_ids = torch.tensor([[decoder_start_token]], dtype=torch.long)\n",
    "\n",
    "iterations = []\n",
    "with torch.no_grad():\n",
    "    for _ in range(n_steps):\n",
    "        iteration = {}\n",
    "        # the first row\n",
    "        iteration['input'] = tokenizer.decode(input_ids[0])\n",
    "        encoder_outputs = model.get_encoder()(input_ids)\n",
    "        decoder_outputs = model.get_decoder()(input_ids=decoder_input_ids, \n",
    "                                              encoder_hidden_states=encoder_outputs.last_hidden_state)\n",
    "        last_token_logits = decoder_outputs.last_hidden_state[0, -1, :]\n",
    "        last_token_prob = torch.softmax(last_token_logits, dim=-1)\n",
    "        sorted_ids = torch.argsort(last_token_prob, dim=-1, descending=True)\n",
    "        for choice_idx in range(top_x):\n",
    "            token_id = sorted_ids[top_x]\n",
    "            token_prob = last_token_prob[token_id]\n",
    "            token_choice = f'{tokenizer.decode(token_id)}({100*token_prob:.2f}%)'\n",
    "            iteration[f'choice {choice_idx + 1}'] = token_choice\n",
    "        \n",
    "        print('before append input_ids.shape', input_ids.shape)\n",
    "        input_ids = torch.cat([input_ids, sorted_ids[None, 0, None]], dim=-1)\n",
    "        print('after append input_ids.shape', input_ids.shape)\n",
    "        \n",
    "        iterations.append(iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23dd0939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>choice 1</th>\n",
       "      <th>choice 2</th>\n",
       "      <th>choice 3</th>\n",
       "      <th>choice 4</th>\n",
       "      <th>choice 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt;The Bart model was proposed in BART: Denois...</td>\n",
       "      <td>club(0.15%)</td>\n",
       "      <td>club(0.15%)</td>\n",
       "      <td>club(0.15%)</td>\n",
       "      <td>club(0.15%)</td>\n",
       "      <td>club(0.15%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;s&gt;The Bart model was proposed in BART: Denois...</td>\n",
       "      <td>club(0.16%)</td>\n",
       "      <td>club(0.16%)</td>\n",
       "      <td>club(0.16%)</td>\n",
       "      <td>club(0.16%)</td>\n",
       "      <td>club(0.16%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;s&gt;The Bart model was proposed in BART: Denois...</td>\n",
       "      <td>club(0.16%)</td>\n",
       "      <td>club(0.16%)</td>\n",
       "      <td>club(0.16%)</td>\n",
       "      <td>club(0.16%)</td>\n",
       "      <td>club(0.16%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;s&gt;The Bart model was proposed in BART: Denois...</td>\n",
       "      <td>club(0.15%)</td>\n",
       "      <td>club(0.15%)</td>\n",
       "      <td>club(0.15%)</td>\n",
       "      <td>club(0.15%)</td>\n",
       "      <td>club(0.15%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;s&gt;The Bart model was proposed in BART: Denois...</td>\n",
       "      <td>club(0.15%)</td>\n",
       "      <td>club(0.15%)</td>\n",
       "      <td>club(0.15%)</td>\n",
       "      <td>club(0.15%)</td>\n",
       "      <td>club(0.15%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;s&gt;The Bart model was proposed in BART: Denois...</td>\n",
       "      <td>club(0.15%)</td>\n",
       "      <td>club(0.15%)</td>\n",
       "      <td>club(0.15%)</td>\n",
       "      <td>club(0.15%)</td>\n",
       "      <td>club(0.15%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;s&gt;The Bart model was proposed in BART: Denois...</td>\n",
       "      <td>club(0.15%)</td>\n",
       "      <td>club(0.15%)</td>\n",
       "      <td>club(0.15%)</td>\n",
       "      <td>club(0.15%)</td>\n",
       "      <td>club(0.15%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;s&gt;The Bart model was proposed in BART: Denois...</td>\n",
       "      <td>club(0.15%)</td>\n",
       "      <td>club(0.15%)</td>\n",
       "      <td>club(0.15%)</td>\n",
       "      <td>club(0.15%)</td>\n",
       "      <td>club(0.15%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;s&gt;The Bart model was proposed in BART: Denois...</td>\n",
       "      <td>club(0.15%)</td>\n",
       "      <td>club(0.15%)</td>\n",
       "      <td>club(0.15%)</td>\n",
       "      <td>club(0.15%)</td>\n",
       "      <td>club(0.15%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;s&gt;The Bart model was proposed in BART: Denois...</td>\n",
       "      <td>club(0.15%)</td>\n",
       "      <td>club(0.15%)</td>\n",
       "      <td>club(0.15%)</td>\n",
       "      <td>club(0.15%)</td>\n",
       "      <td>club(0.15%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input      choice 1  \\\n",
       "0  <s>The Bart model was proposed in BART: Denois...   club(0.15%)   \n",
       "1  <s>The Bart model was proposed in BART: Denois...   club(0.16%)   \n",
       "2  <s>The Bart model was proposed in BART: Denois...   club(0.16%)   \n",
       "3  <s>The Bart model was proposed in BART: Denois...   club(0.15%)   \n",
       "4  <s>The Bart model was proposed in BART: Denois...   club(0.15%)   \n",
       "5  <s>The Bart model was proposed in BART: Denois...   club(0.15%)   \n",
       "6  <s>The Bart model was proposed in BART: Denois...   club(0.15%)   \n",
       "7  <s>The Bart model was proposed in BART: Denois...   club(0.15%)   \n",
       "8  <s>The Bart model was proposed in BART: Denois...   club(0.15%)   \n",
       "9  <s>The Bart model was proposed in BART: Denois...   club(0.15%)   \n",
       "\n",
       "       choice 2      choice 3      choice 4      choice 5  \n",
       "0   club(0.15%)   club(0.15%)   club(0.15%)   club(0.15%)  \n",
       "1   club(0.16%)   club(0.16%)   club(0.16%)   club(0.16%)  \n",
       "2   club(0.16%)   club(0.16%)   club(0.16%)   club(0.16%)  \n",
       "3   club(0.15%)   club(0.15%)   club(0.15%)   club(0.15%)  \n",
       "4   club(0.15%)   club(0.15%)   club(0.15%)   club(0.15%)  \n",
       "5   club(0.15%)   club(0.15%)   club(0.15%)   club(0.15%)  \n",
       "6   club(0.15%)   club(0.15%)   club(0.15%)   club(0.15%)  \n",
       "7   club(0.15%)   club(0.15%)   club(0.15%)   club(0.15%)  \n",
       "8   club(0.15%)   club(0.15%)   club(0.15%)   club(0.15%)  \n",
       "9   club(0.15%)   club(0.15%)   club(0.15%)   club(0.15%)  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020bf74c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
