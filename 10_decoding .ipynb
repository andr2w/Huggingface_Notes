{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7299498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scienceplots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(['science', 'notebook', 'grid', 'ieee'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f4f8b1",
   "metadata": {},
   "source": [
    "- Converting the model's probabilistic output (vocab size classification) to text (token)\n",
    "    - Iteratively, means more computation cost\n",
    "    - Quality & diversity important\n",
    "- Two algorithms to use:\n",
    "    - Greedy search decoding.\n",
    "    - Beam search decoding.\n",
    "- Sampling methods\n",
    "- Top-k & nucleus sampling\n",
    "\n",
    "\n",
    "- Autoregressive language models.\n",
    "- $\\mathbf{x} = \\{x_1, ..., x_k\\}$.\n",
    "- $\\mathbf{y} = \\{y_1, ..., y_t\\}$.\n",
    "    - chain rule of probability to factorize it as a product of conditional probabilities.\n",
    "\n",
    "\n",
    "- Detailed encoding\n",
    "$$p(y_t=w_i\\mid y_{<t}, x) = \\text{softmax}(z_{t, i})$$\n",
    "$$\\hat{y}_t = \\text{argmax}_{y_i}P(y_t \\mid y_{<t, x}) (y_{<t} = y_{1,2,..., t-1})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e06e43",
   "metadata": {},
   "source": [
    "#### Decoding \n",
    "\n",
    "- Greedy search decoding: 重复性较高, 多样性不足, 整体未必是最优解 (输入法都选1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8853978c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c890ebac9b451e9463cfbcfabe05f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/6.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "751b99b440e84365a5be6392ce6ce360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "# GPT2 + language model head\n",
    "model_name = 'gpt2-xl'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e277a7b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  32,  890,  890,  640, 2084,   11]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = 'A long long time ago,'\n",
    "model_inputs = tokenizer(sample_text, return_tensors='pt')\n",
    "input_ids = model_inputs['input_ids']\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e6f30c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  32,  890,  890,  640, 2084,   11])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61eb5747",
   "metadata": {},
   "source": [
    "#### Greedy search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9195bc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before append input_ids.shape torch.Size([1, 6])\n",
      "after append input_ids.shape torch.Size([1, 7])\n",
      "before append input_ids.shape torch.Size([1, 7])\n",
      "after append input_ids.shape torch.Size([1, 8])\n",
      "before append input_ids.shape torch.Size([1, 8])\n",
      "after append input_ids.shape torch.Size([1, 9])\n",
      "before append input_ids.shape torch.Size([1, 9])\n",
      "after append input_ids.shape torch.Size([1, 10])\n",
      "before append input_ids.shape torch.Size([1, 10])\n",
      "after append input_ids.shape torch.Size([1, 11])\n",
      "before append input_ids.shape torch.Size([1, 11])\n",
      "after append input_ids.shape torch.Size([1, 12])\n",
      "before append input_ids.shape torch.Size([1, 12])\n",
      "after append input_ids.shape torch.Size([1, 13])\n",
      "before append input_ids.shape torch.Size([1, 13])\n",
      "after append input_ids.shape torch.Size([1, 14])\n",
      "before append input_ids.shape torch.Size([1, 14])\n",
      "after append input_ids.shape torch.Size([1, 15])\n",
      "before append input_ids.shape torch.Size([1, 15])\n",
      "after append input_ids.shape torch.Size([1, 16])\n"
     ]
    }
   ],
   "source": [
    "n_steps = 10\n",
    "# top 5\n",
    "choices_per_step = 5\n",
    "\n",
    "iterations = []\n",
    "with torch.no_grad():\n",
    "    for _ in range(n_steps):\n",
    "        iteration = {}\n",
    "        iteration['input'] = tokenizer.decode(input_ids[0])\n",
    "\n",
    "        output = model(input_ids=input_ids)\n",
    "\n",
    "        last_token_logits = output.logits[0, -1, :]\n",
    "        last_token_probs = torch.softmax(last_token_logits, dim=-1)\n",
    "        sorted_ids = torch.argsort(last_token_probs, dim=-1, descending=True)\n",
    "\n",
    "        for choice_idx in range(choices_per_step):\n",
    "            token_id = sorted_ids[choice_idx]\n",
    "            token_prob = last_token_probs[token_id]\n",
    "            token_choice = f'{tokenizer.decode(token_id)}({100*token_prob:.2f}%)'\n",
    "            iteration[f'choice {choice_idx +1}'] = token_choice\n",
    "\n",
    "        # append\n",
    "        print('before append input_ids.shape', input_ids.shape)\n",
    "        input_ids = torch.cat([input_ids, sorted_ids[None, 0, None]], dim=-1)\n",
    "        print('after append input_ids.shape', input_ids.shape)\n",
    "\n",
    "        iterations.append(iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c000119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>choice 1</th>\n",
       "      <th>choice 2</th>\n",
       "      <th>choice 3</th>\n",
       "      <th>choice 4</th>\n",
       "      <th>choice 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A long long time ago,</td>\n",
       "      <td>in(23.47%)</td>\n",
       "      <td>I(9.72%)</td>\n",
       "      <td>there(7.42%)</td>\n",
       "      <td>the(5.44%)</td>\n",
       "      <td>a(5.23%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A long long time ago, in</td>\n",
       "      <td>a(80.26%)</td>\n",
       "      <td>the(6.61%)</td>\n",
       "      <td>an(4.45%)</td>\n",
       "      <td>another(0.85%)</td>\n",
       "      <td>my(0.24%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A long long time ago, in a</td>\n",
       "      <td>galaxy(50.88%)</td>\n",
       "      <td>land(11.56%)</td>\n",
       "      <td>far(2.65%)</td>\n",
       "      <td>place(2.60%)</td>\n",
       "      <td>kingdom(2.51%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A long long time ago, in a galaxy</td>\n",
       "      <td>far(90.35%)</td>\n",
       "      <td>not(5.81%)</td>\n",
       "      <td>very(0.62%)</td>\n",
       "      <td>that(0.35%)</td>\n",
       "      <td>much(0.28%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A long long time ago, in a galaxy far</td>\n",
       "      <td>,(88.23%)</td>\n",
       "      <td>far(8.82%)</td>\n",
       "      <td>away(2.12%)</td>\n",
       "      <td>distant(0.14%)</td>\n",
       "      <td>,(0.03%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A long long time ago, in a galaxy far,</td>\n",
       "      <td>far(99.57%)</td>\n",
       "      <td>distant(0.05%)</td>\n",
       "      <td>Far(0.05%)</td>\n",
       "      <td>very(0.05%)</td>\n",
       "      <td>long(0.04%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A long long time ago, in a galaxy far, far</td>\n",
       "      <td>away(97.65%)</td>\n",
       "      <td>,(1.90%)</td>\n",
       "      <td>distant(0.05%)</td>\n",
       "      <td>far(0.05%)</td>\n",
       "      <td>Away(0.05%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A long long time ago, in a galaxy far, far away</td>\n",
       "      <td>,(26.92%)</td>\n",
       "      <td>...(19.00%)</td>\n",
       "      <td>…(13.21%)</td>\n",
       "      <td>.(5.36%)</td>\n",
       "      <td>…\"(4.21%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A long long time ago, in a galaxy far, far away,</td>\n",
       "      <td>there(20.43%)</td>\n",
       "      <td>a(18.31%)</td>\n",
       "      <td>the(8.79%)</td>\n",
       "      <td>in(5.54%)</td>\n",
       "      <td>I(3.01%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A long long time ago, in a galaxy far, far awa...</td>\n",
       "      <td>was(66.84%)</td>\n",
       "      <td>lived(18.80%)</td>\n",
       "      <td>were(6.99%)</td>\n",
       "      <td>existed(1.50%)</td>\n",
       "      <td>once(1.04%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input         choice 1  \\\n",
       "0                              A long long time ago,       in(23.47%)   \n",
       "1                           A long long time ago, in        a(80.26%)   \n",
       "2                         A long long time ago, in a   galaxy(50.88%)   \n",
       "3                  A long long time ago, in a galaxy      far(90.35%)   \n",
       "4              A long long time ago, in a galaxy far        ,(88.23%)   \n",
       "5             A long long time ago, in a galaxy far,      far(99.57%)   \n",
       "6         A long long time ago, in a galaxy far, far     away(97.65%)   \n",
       "7    A long long time ago, in a galaxy far, far away        ,(26.92%)   \n",
       "8   A long long time ago, in a galaxy far, far away,    there(20.43%)   \n",
       "9  A long long time ago, in a galaxy far, far awa...      was(66.84%)   \n",
       "\n",
       "          choice 2         choice 3         choice 4         choice 5  \n",
       "0         I(9.72%)     there(7.42%)       the(5.44%)         a(5.23%)  \n",
       "1       the(6.61%)        an(4.45%)   another(0.85%)        my(0.24%)  \n",
       "2     land(11.56%)       far(2.65%)     place(2.60%)   kingdom(2.51%)  \n",
       "3       not(5.81%)      very(0.62%)      that(0.35%)      much(0.28%)  \n",
       "4       far(8.82%)      away(2.12%)   distant(0.14%)         ,(0.03%)  \n",
       "5   distant(0.05%)       Far(0.05%)      very(0.05%)      long(0.04%)  \n",
       "6         ,(1.90%)   distant(0.05%)       far(0.05%)      Away(0.05%)  \n",
       "7      ...(19.00%)        …(13.21%)         .(5.36%)        …\"(4.21%)  \n",
       "8        a(18.31%)       the(8.79%)        in(5.54%)         I(3.01%)  \n",
       "9    lived(18.80%)      were(6.99%)   existed(1.50%)      once(1.04%)  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea22c2b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
