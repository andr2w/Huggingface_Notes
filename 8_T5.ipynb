{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "898c078d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModel\n",
    "# ~/.cache/huggingface/hub\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scienceplots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(['science', 'notebook', 'grid', 'ieee'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66ba491",
   "metadata": {},
   "source": [
    "- t5: text-to-text transfer transformer\n",
    "    - https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html\n",
    "    - https://huggingface.co/docs/transformers/model_doc/t5\n",
    "- Model size\n",
    "    - t5-small, 512 (64*8)\n",
    "    - t5-base, 768 (64*12)\n",
    "    - t5-large, 1024 (64*16)\n",
    "    - t5-3b, 4096 (128*32)\n",
    "    - t5-11b, 16384 (128*128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80602a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8383f35b04754413bbc055c1452e7f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/anaconda3/lib/python3.11/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5Config {\n",
       "  \"_name_or_path\": \"t5-base\",\n",
       "  \"architectures\": [\n",
       "    \"T5ForConditionalGeneration\"\n",
       "  ],\n",
       "  \"d_ff\": 3072,\n",
       "  \"d_kv\": 64,\n",
       "  \"d_model\": 768,\n",
       "  \"decoder_start_token_id\": 0,\n",
       "  \"dense_act_fn\": \"relu\",\n",
       "  \"dropout_rate\": 0.1,\n",
       "  \"eos_token_id\": 1,\n",
       "  \"feed_forward_proj\": \"relu\",\n",
       "  \"initializer_factor\": 1.0,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"is_gated_act\": false,\n",
       "  \"layer_norm_epsilon\": 1e-06,\n",
       "  \"model_type\": \"t5\",\n",
       "  \"n_positions\": 512,\n",
       "  \"num_decoder_layers\": 12,\n",
       "  \"num_heads\": 12,\n",
       "  \"num_layers\": 12,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"relative_attention_max_distance\": 128,\n",
       "  \"relative_attention_num_buckets\": 32,\n",
       "  \"task_specific_params\": {\n",
       "    \"summarization\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"length_penalty\": 2.0,\n",
       "      \"max_length\": 200,\n",
       "      \"min_length\": 30,\n",
       "      \"no_repeat_ngram_size\": 3,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"summarize: \"\n",
       "    },\n",
       "    \"translation_en_to_de\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to German: \"\n",
       "    },\n",
       "    \"translation_en_to_fr\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to French: \"\n",
       "    },\n",
       "    \"translation_en_to_ro\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to Romanian: \"\n",
       "    }\n",
       "  },\n",
       "  \"transformers_version\": \"4.31.0\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 32128\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 't5-base'\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba6e9172",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5Model(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4966f8f7",
   "metadata": {},
   "source": [
    "#### Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "19909a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[6536,   43,  118, 2008,   24,  293,   53,    3,    9, 1782,   19,  207,\n",
       "            21,   25,    1]]),\n",
       " 15)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Studies have been shown that owning a dog is good for you'\n",
    "batch_inputs = tokenizer(text, return_tensors='pt')\n",
    "input_ids = batch_inputs['input_ids']\n",
    "input_ids, len(*input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "af9126e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6536,  504,   24,    1]])\n",
      "tensor([[   0, 6536,  504,   24]])\n"
     ]
    }
   ],
   "source": [
    "decoder_input_ids = tokenizer('Studies show that', return_tensors='pt')\n",
    "decoder_input_ids = decoder_input_ids['input_ids']\n",
    "print(decoder_input_ids)\n",
    "decoder_input_ids = model._shift_right(decoder_input_ids)\n",
    "print(decoder_input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0895d433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.0991,  0.1743, -0.1142,  ..., -0.0117,  0.0558,  0.1053],\n",
       "          [ 0.0314, -0.1558,  0.0109,  ..., -0.0440, -0.0196, -0.0842],\n",
       "          [-0.1150, -0.1574,  0.0051,  ..., -0.0378, -0.0137, -0.0972],\n",
       "          [-0.1110,  0.0093, -0.0019,  ...,  0.0514,  0.0396, -0.0774]]],\n",
       "        grad_fn=<MulBackward0>),\n",
       " torch.Size([1, 4, 768]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "# forward pass\n",
    "outputs = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids)\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "last_hidden_states, last_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f8001859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 15, 768])\n"
     ]
    }
   ],
   "source": [
    "# Details in the T5 forward\n",
    "encoder_outputs = model.encoder(input_ids=input_ids)\n",
    "hidden_states = encoder_outputs[0]\n",
    "print(hidden_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4a08dd30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0991,  0.1743, -0.1142,  ..., -0.0117,  0.0558,  0.1053],\n",
       "         [ 0.0314, -0.1558,  0.0109,  ..., -0.0440, -0.0196, -0.0842],\n",
       "         [-0.1150, -0.1574,  0.0051,  ..., -0.0378, -0.0137, -0.0972],\n",
       "         [-0.1110,  0.0093, -0.0019,  ...,  0.0514,  0.0396, -0.0774]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_outputs = model.decoder(input_ids=decoder_input_ids, encoder_hidden_states=hidden_states)\n",
    "decoder_last_hidden_states = decoder_outputs.last_hidden_state\n",
    "decoder_last_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "785ea366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states == decoder_last_hidden_states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013acbd0",
   "metadata": {},
   "source": [
    "#### If we are doing a inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1047cdf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[30355,    15,    34,    10,  6536,    43,   118,  2008,    24,   293,\n",
       "             53,     3,     9,  1782,    19,   207,    21,    25,     5,     1]]),\n",
       " 20)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Translate it: Studies have been shown that owning a dog is good for you.'\n",
    "batch_inputs = tokenizer(text, return_tensors='pt')\n",
    "input_ids = batch_inputs['input_ids']\n",
    "input_ids, len(*input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "63a4fabb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(BaseModelOutputWithPastAndCrossAttentions(last_hidden_state=tensor([[[ 0.0902, -0.1033, -0.4092,  ...,  0.0406,  0.0204, -0.1073],\n",
       "          [ 0.0528,  0.0487, -0.2332,  ..., -0.2115, -0.0991, -0.3346],\n",
       "          [-0.0057, -0.0381, -0.2648,  ..., -0.3037, -0.1655, -0.3205],\n",
       "          ...,\n",
       "          [ 0.4811,  0.0481, -0.4502,  ..., -0.1001, -0.2813, -0.2189],\n",
       "          [ 0.4262,  0.1389, -0.5530,  ..., -0.2203, -0.0630,  0.0804],\n",
       "          [ 0.0226, -0.0007, -0.0135,  ..., -0.0020,  0.0204, -0.0342]]],\n",
       "        grad_fn=<MulBackward0>), past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None),\n",
       " torch.Size([1, 15, 768]))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_ouputs = model.get_encoder()(input_ids)\n",
    "encoder_outputs, encoder_outputs.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d81335da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'can'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_start_token = model.config.decoder_start_token_id\n",
    "decoder_input_ids = torch.tensor([[decoder_start_token]], dtype=torch.long)\n",
    "\n",
    "decoder_outputs = model.get_decoder()(input_ids=decoder_input_ids, \n",
    "                                      encoder_hidden_states=encoder_output.last_hidden_state)\n",
    "\n",
    "# decoder_outputs.keys()\n",
    "output_tokens = decoder_outputs[0]\n",
    "probabilites = F.softmax(output_tokens, dim=-1)\n",
    "next_token_id = torch.argmax(probabilites, dim=-1).item()\n",
    "output_text = tokenizer.decode([next_token_id])\n",
    "#print(output_tokens.shape)\n",
    "#print(output_tokens)\n",
    "#output_text = tokenizer.decode(output_tokens[0][0].tolist())\n",
    "output_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06ae473",
   "metadata": {},
   "source": [
    "#### To the next word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f1ca30d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[54, 54, 484, 86, 86, 86, 54, 484, 86, 54, 86, 54, 86, 54, 86, 54, 86, 54, 86, 54, 86, 54, 86, 54, 86, 54, 86, 54, 86, 54, 86, 54, 86, 54, 86, 54, 219, 54, 219, 54, 219, 54, 219, 54, 219, 54, 219, 54, 219, 54, 219, 54, 219, 54, 219, 54, 219, 86, 219, 219, 54, 219, 219, 54, 219, 86, 54, 219, 54, 219, 54, 219, 54, 219, 54, 219, 54, 219, 219, 54, 219, 86, 219, 219, 54, 219, 219, 54, 219, 219, 54, 219, 219, 54, 219, 86, 54, 219, 54, 219]\n"
     ]
    }
   ],
   "source": [
    "decoder_start_token = model.config.decoder_start_token_id\n",
    "decoder_input_ids = torch.tensor([[decoder_start_token]], dtype=torch.long)\n",
    "\n",
    "generated_tokens = []\n",
    "\n",
    "for _ in range(100): # maximum length of the output sequence\n",
    "    decoder_outputs = model.get_decoder()(input_ids=decoder_input_ids, \n",
    "                                          encoder_hidden_states=encoder_output.last_hidden_state)\n",
    "    logits = decoder_outputs[0]\n",
    "    next_token_id = logits.argmax(-1)[:, -1]\n",
    "    decoder_input_ids = torch.cat([decoder_input_ids, next_token_id.unsqueeze(-1)], dim=-1)\n",
    "    generated_tokens.append(next_token_id.item())\n",
    "    if next_token_id.item() == tokenizer.eos_token_id:\n",
    "        break\n",
    "\n",
    "print(generated_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a4b80671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'can can book In In In can book In can In can In can In can In can In can In can In can In can In can In can In can In can In can auf can auf can auf can auf can auf can auf can auf can auf can auf can auf can auf In auf auf can auf auf can auf In can auf can auf can auf can auf can auf can auf auf can auf In auf auf can auf auf can auf auf can auf auf can auf In can auf can auf'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_text = tokenizer.decode(generated_tokens)\n",
    "output_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54bd961",
   "metadata": {},
   "source": [
    "#### Using a bigger model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "74b61e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "55815733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> Studien haben gezeigt, dass der Besitz eines Hundes gut für Sie ist.</s>'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Translate English to German: Studies have been shown that owning a dog is good for you.'\n",
    "input_ids = tokenizer.encode(text, return_tensors=\"pt\") \n",
    "result = model.generate(input_ids)\n",
    "tokenizer.decode(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "63ce2823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> Hallo, mein Hund ist süß</s>'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(\"translate English to German: Hello, my dog is cute\", return_tensors=\"pt\") \n",
    "result = model.generate(input_ids)\n",
    "tokenizer.decode(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0f1e3ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> What is the correct part of this sentence?</s>'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Tell me which part of this sentence is true?:Studies have been shown that owning a dog is good for you.'\n",
    "input_ids = tokenizer.encode(text, return_tensors=\"pt\") \n",
    "result = model.generate(input_ids)\n",
    "tokenizer.decode(result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd521f9d",
   "metadata": {},
   "source": [
    "#### Greedy search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2355dbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = 'A long long time ago,'\n",
    "model_inputs = tokenizer(sample_text, return_tensors='pt')\n",
    "input_ids = model_inputs.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "264358cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before append input_ids.shape torch.Size([1, 7])\n",
      "after append input_ids.shape torch.Size([1, 8])\n",
      "before append input_ids.shape torch.Size([1, 8])\n",
      "after append input_ids.shape torch.Size([1, 9])\n",
      "before append input_ids.shape torch.Size([1, 9])\n",
      "after append input_ids.shape torch.Size([1, 10])\n",
      "before append input_ids.shape torch.Size([1, 10])\n",
      "after append input_ids.shape torch.Size([1, 11])\n",
      "before append input_ids.shape torch.Size([1, 11])\n",
      "after append input_ids.shape torch.Size([1, 12])\n",
      "before append input_ids.shape torch.Size([1, 12])\n",
      "after append input_ids.shape torch.Size([1, 13])\n",
      "before append input_ids.shape torch.Size([1, 13])\n",
      "after append input_ids.shape torch.Size([1, 14])\n",
      "before append input_ids.shape torch.Size([1, 14])\n",
      "after append input_ids.shape torch.Size([1, 15])\n",
      "before append input_ids.shape torch.Size([1, 15])\n",
      "after append input_ids.shape torch.Size([1, 16])\n",
      "before append input_ids.shape torch.Size([1, 16])\n",
      "after append input_ids.shape torch.Size([1, 17])\n"
     ]
    }
   ],
   "source": [
    "n_steps = 10\n",
    "top_x = 5\n",
    "\n",
    "\n",
    "decoder_start_token = model.config.decoder_start_token_id\n",
    "decoder_input_ids = torch.tensor([[decoder_start_token]], dtype=torch.long)\n",
    "\n",
    "iterations = []\n",
    "with torch.no_grad():\n",
    "    for _ in range(n_steps):\n",
    "        iteration = {}\n",
    "        # the first row\n",
    "        iteration['input'] = tokenizer.decode(input_ids[0])\n",
    "        encoder_outputs = model.get_encoder()(input_ids)\n",
    "        decoder_outputs = model.get_decoder()(input_ids=decoder_input_ids, \n",
    "                                              encoder_hidden_states=encoder_outputs.last_hidden_state)\n",
    "        last_token_logits = decoder_outputs.last_hidden_state[0, -1, :]\n",
    "        last_token_prob = torch.softmax(last_token_logits, dim=-1)\n",
    "        sorted_ids = torch.argsort(last_token_prob, dim=-1, descending=True)\n",
    "        for choice_idx in range(top_x):\n",
    "            token_id = sorted_ids[top_x]\n",
    "            token_prob = last_token_prob[token_id]\n",
    "            token_choice = f'{tokenizer.decode(token_id)}({100*token_prob:.2f}%)'\n",
    "            iteration[f'choice {choice_idx + 1}'] = token_choice\n",
    "        \n",
    "        print('before append input_ids.shape', input_ids.shape)\n",
    "        input_ids = torch.cat([input_ids, sorted_ids[None, 0, None]], dim=-1)\n",
    "        print('after append input_ids.shape', input_ids.shape)\n",
    "        \n",
    "        iterations.append(iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6aa3dc37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>choice 1</th>\n",
       "      <th>choice 2</th>\n",
       "      <th>choice 3</th>\n",
       "      <th>choice 4</th>\n",
       "      <th>choice 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A long long time ago,&lt;/s&gt;</td>\n",
       "      <td>V(0.01%)</td>\n",
       "      <td>V(0.01%)</td>\n",
       "      <td>V(0.01%)</td>\n",
       "      <td>V(0.01%)</td>\n",
       "      <td>V(0.01%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A long long time ago,&lt;/s&gt; can</td>\n",
       "      <td>V(0.01%)</td>\n",
       "      <td>V(0.01%)</td>\n",
       "      <td>V(0.01%)</td>\n",
       "      <td>V(0.01%)</td>\n",
       "      <td>V(0.01%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A long long time ago,&lt;/s&gt; can can</td>\n",
       "      <td>V(0.01%)</td>\n",
       "      <td>V(0.01%)</td>\n",
       "      <td>V(0.01%)</td>\n",
       "      <td>V(0.01%)</td>\n",
       "      <td>V(0.01%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A long long time ago,&lt;/s&gt; can can can</td>\n",
       "      <td>has(0.01%)</td>\n",
       "      <td>has(0.01%)</td>\n",
       "      <td>has(0.01%)</td>\n",
       "      <td>has(0.01%)</td>\n",
       "      <td>has(0.01%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A long long time ago,&lt;/s&gt; can can can can</td>\n",
       "      <td>has(0.02%)</td>\n",
       "      <td>has(0.02%)</td>\n",
       "      <td>has(0.02%)</td>\n",
       "      <td>has(0.02%)</td>\n",
       "      <td>has(0.02%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A long long time ago,&lt;/s&gt; can can can can can</td>\n",
       "      <td>has(0.03%)</td>\n",
       "      <td>has(0.03%)</td>\n",
       "      <td>has(0.03%)</td>\n",
       "      <td>has(0.03%)</td>\n",
       "      <td>has(0.03%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A long long time ago,&lt;/s&gt; can can can can can can</td>\n",
       "      <td>has(0.03%)</td>\n",
       "      <td>has(0.03%)</td>\n",
       "      <td>has(0.03%)</td>\n",
       "      <td>has(0.03%)</td>\n",
       "      <td>has(0.03%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A long long time ago,&lt;/s&gt; can can can can can ...</td>\n",
       "      <td>has(0.04%)</td>\n",
       "      <td>has(0.04%)</td>\n",
       "      <td>has(0.04%)</td>\n",
       "      <td>has(0.04%)</td>\n",
       "      <td>has(0.04%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A long long time ago,&lt;/s&gt; can can can can can ...</td>\n",
       "      <td>has(0.03%)</td>\n",
       "      <td>has(0.03%)</td>\n",
       "      <td>has(0.03%)</td>\n",
       "      <td>has(0.03%)</td>\n",
       "      <td>has(0.03%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A long long time ago,&lt;/s&gt; can can can can can ...</td>\n",
       "      <td>In(0.04%)</td>\n",
       "      <td>In(0.04%)</td>\n",
       "      <td>In(0.04%)</td>\n",
       "      <td>In(0.04%)</td>\n",
       "      <td>In(0.04%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input    choice 1    choice 2  \\\n",
       "0                          A long long time ago,</s>    V(0.01%)    V(0.01%)   \n",
       "1                      A long long time ago,</s> can    V(0.01%)    V(0.01%)   \n",
       "2                  A long long time ago,</s> can can    V(0.01%)    V(0.01%)   \n",
       "3              A long long time ago,</s> can can can  has(0.01%)  has(0.01%)   \n",
       "4          A long long time ago,</s> can can can can  has(0.02%)  has(0.02%)   \n",
       "5      A long long time ago,</s> can can can can can  has(0.03%)  has(0.03%)   \n",
       "6  A long long time ago,</s> can can can can can can  has(0.03%)  has(0.03%)   \n",
       "7  A long long time ago,</s> can can can can can ...  has(0.04%)  has(0.04%)   \n",
       "8  A long long time ago,</s> can can can can can ...  has(0.03%)  has(0.03%)   \n",
       "9  A long long time ago,</s> can can can can can ...   In(0.04%)   In(0.04%)   \n",
       "\n",
       "     choice 3    choice 4    choice 5  \n",
       "0    V(0.01%)    V(0.01%)    V(0.01%)  \n",
       "1    V(0.01%)    V(0.01%)    V(0.01%)  \n",
       "2    V(0.01%)    V(0.01%)    V(0.01%)  \n",
       "3  has(0.01%)  has(0.01%)  has(0.01%)  \n",
       "4  has(0.02%)  has(0.02%)  has(0.02%)  \n",
       "5  has(0.03%)  has(0.03%)  has(0.03%)  \n",
       "6  has(0.03%)  has(0.03%)  has(0.03%)  \n",
       "7  has(0.04%)  has(0.04%)  has(0.04%)  \n",
       "8  has(0.03%)  has(0.03%)  has(0.03%)  \n",
       "9   In(0.04%)   In(0.04%)   In(0.04%)  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(iterations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
