{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ef2191e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28e3195",
   "metadata": {},
   "source": [
    "| Model  | # of Parameters | Hidden dim | # of blocks|\n",
    "|-------|-----|--------| --------|\n",
    "| gpt2 | 124M  | 768 /(64 * 12/)| 12|\n",
    "| gpt2-medium | 355M | 1024 /(64 * 16/) | 24|\n",
    "| gpt2-large | 774M | 1280 /(64 * 20/) | 36 |\n",
    "|gpt2-xl | 1.56B | 1600 /(64 * 25/) | 48|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6f92d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8f57bad472c4c3091b4711a48081c8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a836e9d7ab54337bd1b21fc4519292c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "980278276e1c4aea9c0a6c5813a85f56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model_name = 'gpt2'\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "model_clm = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca37c184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Model(\n",
       "  (wte): Embedding(50257, 1600)\n",
       "  (wpe): Embedding(1024, 1600)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (h): ModuleList(\n",
       "    (0-47): 48 x GPT2Block(\n",
       "      (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (act): NewGELUActivation()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24a2714f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Config {\n",
       "  \"_name_or_path\": \"gpt2-large\",\n",
       "  \"activation_function\": \"gelu_new\",\n",
       "  \"architectures\": [\n",
       "    \"GPT2LMHeadModel\"\n",
       "  ],\n",
       "  \"attn_pdrop\": 0.1,\n",
       "  \"bos_token_id\": 50256,\n",
       "  \"embd_pdrop\": 0.1,\n",
       "  \"eos_token_id\": 50256,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"model_type\": \"gpt2\",\n",
       "  \"n_ctx\": 1024,\n",
       "  \"n_embd\": 1280,\n",
       "  \"n_head\": 20,\n",
       "  \"n_inner\": null,\n",
       "  \"n_layer\": 36,\n",
       "  \"n_positions\": 1024,\n",
       "  \"reorder_and_upcast_attn\": false,\n",
       "  \"resid_pdrop\": 0.1,\n",
       "  \"scale_attn_by_inverse_layer_idx\": false,\n",
       "  \"scale_attn_weights\": true,\n",
       "  \"summary_activation\": null,\n",
       "  \"summary_first_dropout\": 0.1,\n",
       "  \"summary_proj_to_labels\": true,\n",
       "  \"summary_type\": \"cls_index\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"task_specific_params\": {\n",
       "    \"text-generation\": {\n",
       "      \"do_sample\": true,\n",
       "      \"max_length\": 50\n",
       "    }\n",
       "  },\n",
       "  \"transformers_version\": \"4.31.0\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50257\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6942e0b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 1280)\n",
       "    (wpe): Embedding(1024, 1280)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-35): 36 x GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1280, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_clm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5432efaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2TokenizerFast(name_or_path='gpt2-xl', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f886da81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<|endoftext|>',\n",
       " 'eos_token': '<|endoftext|>',\n",
       " 'unk_token': '<|endoftext|>'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a18f235d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [3666, 4004, 3124, 318, 7510], 'attention_mask': [1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('My favorite color is shit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b4dd875",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"A long long time ago\"\n",
    "model_inputs = tokenizer(text, return_tensors='pt')\n",
    "input_ids = model_inputs.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd898e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model_clm(input_ids = input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d39bb51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['logits', 'past_key_values'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1740885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 50257])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bfd45f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output.past_key_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9553c442",
   "metadata": {},
   "source": [
    "Model.transformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "692b2dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clm.eval()\n",
    "transformer_outputs = model_clm.transformer(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1f672ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 1600])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_outputs.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1389f17a",
   "metadata": {},
   "source": [
    "#### embeddings\n",
    "- wte: word token embeddings\n",
    "- wpe: word position embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7081470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 50257])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_clm.eval()\n",
    "lm_logits = model_clm.lm_head(transformer_outputs.last_hidden_state)\n",
    "lm_logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9d2a1c",
   "metadata": {},
   "source": [
    "#### Greedy Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f57229a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_search(input_ids, model, n_steps, top_x, tokenizer):\n",
    "    iterations = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_steps):\n",
    "            iteration = {}\n",
    "            iteration['input'] = tokenizer.decode(input_ids[0])\n",
    "            \n",
    "            transformer_outputs = model.transformer(input_ids)\n",
    "            lm_logits = model.lm_head(transformer_outputs.last_hidden_state)\n",
    "            last_token_logits = lm_logits[0, -1, :]\n",
    "            last_token_probs = torch.softmax(last_token_logits, dim=-1)\n",
    "            sorted_ids = torch.argsort(last_token_probs, dim=-1, descending=True)\n",
    "            \n",
    "            for choice_idx in range(top_x):\n",
    "                token_id = sorted_ids[choice_idx]\n",
    "                token_prob = last_token_probs[token_id]\n",
    "                token_choice = f'{tokenizer.decode(token_id)}({100*token_prob:.2f}%)'\n",
    "                iteration[f'choice {choice_idx + 1}'] = token_choice\n",
    "            \n",
    "            input_ids = torch.cat([input_ids, sorted_ids[None, 0, None]], dim=-1)\n",
    "            \n",
    "            iterations.append(iteration)\n",
    "    return iterations, input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "618a5e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations, output_ids = greedy_search(input_ids, model_clm, 10, 5, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9d310af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>choice 1</th>\n",
       "      <th>choice 2</th>\n",
       "      <th>choice 3</th>\n",
       "      <th>choice 4</th>\n",
       "      <th>choice 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A long long time ago</td>\n",
       "      <td>,(49.28%)</td>\n",
       "      <td>.(10.40%)</td>\n",
       "      <td>I(4.62%)</td>\n",
       "      <td>the(2.99%)</td>\n",
       "      <td>when(2.35%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A long long time ago,</td>\n",
       "      <td>the(10.04%)</td>\n",
       "      <td>I(9.30%)</td>\n",
       "      <td>when(6.91%)</td>\n",
       "      <td>there(3.95%)</td>\n",
       "      <td>a(3.42%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A long long time ago, the</td>\n",
       "      <td>world(2.49%)</td>\n",
       "      <td>only(1.22%)</td>\n",
       "      <td>first(1.21%)</td>\n",
       "      <td>people(0.99%)</td>\n",
       "      <td>United(0.61%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A long long time ago, the world</td>\n",
       "      <td>was(27.99%)</td>\n",
       "      <td>'s(8.40%)</td>\n",
       "      <td>had(6.56%)</td>\n",
       "      <td>of(6.24%)</td>\n",
       "      <td>would(2.91%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A long long time ago, the world was</td>\n",
       "      <td>a(8.24%)</td>\n",
       "      <td>divided(4.39%)</td>\n",
       "      <td>ruled(3.90%)</td>\n",
       "      <td>in(3.16%)</td>\n",
       "      <td>full(2.84%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A long long time ago, the world was a</td>\n",
       "      <td>land(5.41%)</td>\n",
       "      <td>place(5.12%)</td>\n",
       "      <td>very(2.71%)</td>\n",
       "      <td>little(2.39%)</td>\n",
       "      <td>different(1.85%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A long long time ago, the world was a land</td>\n",
       "      <td>of(81.89%)</td>\n",
       "      <td>where(5.60%)</td>\n",
       "      <td>that(0.88%)</td>\n",
       "      <td>filled(0.84%)</td>\n",
       "      <td>full(0.83%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A long long time ago, the world was a land of</td>\n",
       "      <td>great(1.75%)</td>\n",
       "      <td>the(1.32%)</td>\n",
       "      <td>chaos(1.21%)</td>\n",
       "      <td>peace(1.13%)</td>\n",
       "      <td>giants(1.10%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A long long time ago, the world was a land of ...</td>\n",
       "      <td>wealth(10.26%)</td>\n",
       "      <td>beauty(5.06%)</td>\n",
       "      <td>riches(3.67%)</td>\n",
       "      <td>abundance(3.22%)</td>\n",
       "      <td>power(2.33%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A long long time ago, the world was a land of ...</td>\n",
       "      <td>and(54.78%)</td>\n",
       "      <td>,(24.02%)</td>\n",
       "      <td>.(12.60%)</td>\n",
       "      <td>;(1.38%)</td>\n",
       "      <td>but(0.89%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input         choice 1  \\\n",
       "0                               A long long time ago        ,(49.28%)   \n",
       "1                              A long long time ago,      the(10.04%)   \n",
       "2                          A long long time ago, the     world(2.49%)   \n",
       "3                    A long long time ago, the world      was(27.99%)   \n",
       "4                A long long time ago, the world was         a(8.24%)   \n",
       "5              A long long time ago, the world was a      land(5.41%)   \n",
       "6         A long long time ago, the world was a land       of(81.89%)   \n",
       "7      A long long time ago, the world was a land of     great(1.75%)   \n",
       "8  A long long time ago, the world was a land of ...   wealth(10.26%)   \n",
       "9  A long long time ago, the world was a land of ...      and(54.78%)   \n",
       "\n",
       "          choice 2        choice 3           choice 4           choice 5  \n",
       "0        .(10.40%)        I(4.62%)         the(2.99%)        when(2.35%)  \n",
       "1         I(9.30%)     when(6.91%)       there(3.95%)           a(3.42%)  \n",
       "2      only(1.22%)    first(1.21%)      people(0.99%)      United(0.61%)  \n",
       "3        's(8.40%)      had(6.56%)          of(6.24%)       would(2.91%)  \n",
       "4   divided(4.39%)    ruled(3.90%)          in(3.16%)        full(2.84%)  \n",
       "5     place(5.12%)     very(2.71%)      little(2.39%)   different(1.85%)  \n",
       "6     where(5.60%)     that(0.88%)      filled(0.84%)        full(0.83%)  \n",
       "7       the(1.32%)    chaos(1.21%)       peace(1.13%)      giants(1.10%)  \n",
       "8    beauty(5.06%)   riches(3.67%)   abundance(3.22%)       power(2.33%)  \n",
       "9        ,(24.02%)       .(12.60%)           ;(1.38%)         but(0.89%)  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3b2421",
   "metadata": {},
   "source": [
    "#### Beam Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accc935a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
