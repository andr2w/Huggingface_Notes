{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ef2191e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28e3195",
   "metadata": {},
   "source": [
    "| Model  | # of Parameters | Hidden dim | # of blocks|\n",
    "|-------|-----|--------| --------|\n",
    "| gpt2 | 124M  | 768 /(64 * 12/)| 12|\n",
    "| gpt2-medium | 355M | 1024 /(64 * 16/) | 24|\n",
    "| gpt2-large | 774M | 1280 /(64 * 20/) | 36 |\n",
    "|gpt2-xl | 1.56B | 1600 /(64 * 25/) | 48|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6f92d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model_name = 'gpt2-xl'\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "model_clm = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca37c184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Model(\n",
       "  (wte): Embedding(50257, 1600)\n",
       "  (wpe): Embedding(1024, 1600)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (h): ModuleList(\n",
       "    (0-47): 48 x GPT2Block(\n",
       "      (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (act): NewGELUActivation()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6942e0b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 1600)\n",
       "    (wpe): Embedding(1024, 1600)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-47): 48 x GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1600, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_clm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5432efaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2TokenizerFast(name_or_path='gpt2-xl', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f886da81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<|endoftext|>',\n",
       " 'eos_token': '<|endoftext|>',\n",
       " 'unk_token': '<|endoftext|>'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a18f235d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [3666, 4004, 3124, 318, 7510], 'attention_mask': [1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('My favorite color is shit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b4dd875",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"A long long time ago\"\n",
    "model_inputs = tokenizer(text, return_tensors='pt')\n",
    "input_ids = model_inputs.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd898e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model_clm(input_ids = input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d39bb51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['logits', 'past_key_values'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1740885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 50257])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bfd45f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output.past_key_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9553c442",
   "metadata": {},
   "source": [
    "Model.transformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "692b2dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clm.eval()\n",
    "transformer_outputs = model_clm.transformer(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1f672ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 1600])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_outputs.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1389f17a",
   "metadata": {},
   "source": [
    "#### embeddings\n",
    "- wte: word token embeddings\n",
    "- wpe: word position embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7081470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 50257])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_clm.eval()\n",
    "lm_logits = model_clm.lm_head(transformer_outputs.last_hidden_state)\n",
    "lm_logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9d2a1c",
   "metadata": {},
   "source": [
    "#### Greedy Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f57229a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_search(input_ids, model, n_steps, top_x, tokenizer):\n",
    "    iterations = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_steps):\n",
    "            iteration = {}\n",
    "            iteration['input'] = tokenizer.decode(input_ids[0])\n",
    "            \n",
    "            transformer_outputs = model.transformer(input_ids)\n",
    "            lm_logits = model.lm_head(transformer_outputs.last_hidden_state)\n",
    "            last_token_logits = lm_logits[0, -1, :]\n",
    "            last_token_probs = torch.softmax(last_token_logits, dim=-1)\n",
    "            sorted_ids = torch.argsort(last_token_probs, dim=-1, descending=True)\n",
    "            \n",
    "            for choice_idx in range(top_x):\n",
    "                token_id = sorted_ids[choice_idx]\n",
    "                token_prob = last_token_probs[token_id]\n",
    "                token_choice = f'{tokenizer.decode(token_id)}({100*token_prob:.2f}%)'\n",
    "                iteration[f'choice {choice_idx + 1}'] = token_choice\n",
    "            \n",
    "            input_ids = torch.cat([input_ids, sorted_ids[None, 0, None]], dim=-1)\n",
    "            \n",
    "            iterations.append(iteration)\n",
    "    return iterations, input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "618a5e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations, output_ids = greedy_search(input_ids, model_clm, 10, 5, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c9d310af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>choice 1</th>\n",
       "      <th>choice 2</th>\n",
       "      <th>choice 3</th>\n",
       "      <th>choice 4</th>\n",
       "      <th>choice 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A long long time ago</td>\n",
       "      <td>,(47.04%)</td>\n",
       "      <td>in(13.84%)</td>\n",
       "      <td>I(5.00%)</td>\n",
       "      <td>((3.36%)</td>\n",
       "      <td>...(2.97%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A long long time ago,</td>\n",
       "      <td>in(23.47%)</td>\n",
       "      <td>I(9.72%)</td>\n",
       "      <td>there(7.42%)</td>\n",
       "      <td>the(5.44%)</td>\n",
       "      <td>a(5.23%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A long long time ago, in</td>\n",
       "      <td>a(80.26%)</td>\n",
       "      <td>the(6.61%)</td>\n",
       "      <td>an(4.45%)</td>\n",
       "      <td>another(0.85%)</td>\n",
       "      <td>my(0.24%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A long long time ago, in a</td>\n",
       "      <td>galaxy(50.88%)</td>\n",
       "      <td>land(11.56%)</td>\n",
       "      <td>far(2.65%)</td>\n",
       "      <td>place(2.60%)</td>\n",
       "      <td>kingdom(2.51%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A long long time ago, in a galaxy</td>\n",
       "      <td>far(90.35%)</td>\n",
       "      <td>not(5.81%)</td>\n",
       "      <td>very(0.62%)</td>\n",
       "      <td>that(0.35%)</td>\n",
       "      <td>much(0.28%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A long long time ago, in a galaxy far</td>\n",
       "      <td>,(88.23%)</td>\n",
       "      <td>far(8.82%)</td>\n",
       "      <td>away(2.12%)</td>\n",
       "      <td>distant(0.14%)</td>\n",
       "      <td>,(0.03%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A long long time ago, in a galaxy far,</td>\n",
       "      <td>far(99.57%)</td>\n",
       "      <td>distant(0.05%)</td>\n",
       "      <td>Far(0.05%)</td>\n",
       "      <td>very(0.05%)</td>\n",
       "      <td>long(0.04%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A long long time ago, in a galaxy far, far</td>\n",
       "      <td>away(97.65%)</td>\n",
       "      <td>,(1.90%)</td>\n",
       "      <td>distant(0.05%)</td>\n",
       "      <td>far(0.05%)</td>\n",
       "      <td>Away(0.05%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A long long time ago, in a galaxy far, far away</td>\n",
       "      <td>,(26.92%)</td>\n",
       "      <td>...(19.00%)</td>\n",
       "      <td>…(13.21%)</td>\n",
       "      <td>.(5.36%)</td>\n",
       "      <td>…\"(4.21%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A long long time ago, in a galaxy far, far away,</td>\n",
       "      <td>there(20.43%)</td>\n",
       "      <td>a(18.31%)</td>\n",
       "      <td>the(8.79%)</td>\n",
       "      <td>in(5.54%)</td>\n",
       "      <td>I(3.01%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              input         choice 1  \\\n",
       "0                              A long long time ago        ,(47.04%)   \n",
       "1                             A long long time ago,       in(23.47%)   \n",
       "2                          A long long time ago, in        a(80.26%)   \n",
       "3                        A long long time ago, in a   galaxy(50.88%)   \n",
       "4                 A long long time ago, in a galaxy      far(90.35%)   \n",
       "5             A long long time ago, in a galaxy far        ,(88.23%)   \n",
       "6            A long long time ago, in a galaxy far,      far(99.57%)   \n",
       "7        A long long time ago, in a galaxy far, far     away(97.65%)   \n",
       "8   A long long time ago, in a galaxy far, far away        ,(26.92%)   \n",
       "9  A long long time ago, in a galaxy far, far away,    there(20.43%)   \n",
       "\n",
       "          choice 2         choice 3         choice 4         choice 5  \n",
       "0       in(13.84%)         I(5.00%)         ((3.36%)       ...(2.97%)  \n",
       "1         I(9.72%)     there(7.42%)       the(5.44%)         a(5.23%)  \n",
       "2       the(6.61%)        an(4.45%)   another(0.85%)        my(0.24%)  \n",
       "3     land(11.56%)       far(2.65%)     place(2.60%)   kingdom(2.51%)  \n",
       "4       not(5.81%)      very(0.62%)      that(0.35%)      much(0.28%)  \n",
       "5       far(8.82%)      away(2.12%)   distant(0.14%)         ,(0.03%)  \n",
       "6   distant(0.05%)       Far(0.05%)      very(0.05%)      long(0.04%)  \n",
       "7         ,(1.90%)   distant(0.05%)       far(0.05%)      Away(0.05%)  \n",
       "8      ...(19.00%)        …(13.21%)         .(5.36%)        …\"(4.21%)  \n",
       "9        a(18.31%)       the(8.79%)        in(5.54%)         I(3.01%)  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3b2421",
   "metadata": {},
   "source": [
    "#### Beam Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accc935a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
